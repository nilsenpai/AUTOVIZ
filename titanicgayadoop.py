# -*- coding: utf-8 -*-
"""titanicgayadoop.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18dWMW-npDW5FMao5weaTuG5hy-6axJdf
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import files
from transformers import pipeline

insight_pipeline = pipeline("text2text-generation", model="google/flan-t5-large")

def load_csv():
    uploaded = files.upload()  # Open file upload dialog
    for fn in uploaded.keys():
        df = pd.read_csv(fn)
        print(f"File `{fn}` uploaded successfully.")
        return df

def summarize_data(df):
    summary = {
        'shape': df.shape,
        'columns': df.columns.tolist(),
        'dtypes': df.dtypes.astype(str).to_dict(),
        'missing_values': df.isnull().sum().to_dict(),
        'duplicates': df.duplicated().sum(),
        'describe': df.describe(include='all').to_dict()
    }
    return summary

def clean_data(df):
    df = df.drop_duplicates()
    df = df.fillna("MISSING")
    return df

def save_plot(fig, name):
    fig.savefig(f"{name}.png", bbox_inches='tight')

def generate_visuals(df):
    numeric_cols = df.select_dtypes(include='number').columns
    categorical_cols = df.select_dtypes(include='object').columns

    if len(numeric_cols) > 0:
        for column in numeric_cols:
            fig = plt.figure()
            sns.histplot(df[column], kde=True)
            plt.title(f"Distribution of {column}")
            plt.tight_layout()
            save_plot(fig, f"hist_{column}")
            plt.show()

        if len(numeric_cols) > 1:
            fig = plt.figure(figsize=(10, 8))
            sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')
            plt.title("Correlation Heatmap")
            plt.tight_layout()
            save_plot(fig, "correlation_heatmap")
            plt.show()

    if len(categorical_cols) > 0:
        for column in categorical_cols[:3]:  # Limit to 3
            fig = plt.figure()
            df[column].value_counts().head(10).plot(kind='bar')
            plt.title(f"Top categories in {column}")
            plt.xticks(rotation=45)
            plt.tight_layout()
            save_plot(fig, f"bar_{column}")
            plt.show()

def generate_ai_insights(summary_dict, df):
    try:
        summary_text = "\n".join([f"{k}: {v}" for k, v in summary_dict.items()])
        prompt = f"""
You are a data analyst. Given the dataset summary below, provide a comprehensive and detailed analysis of the dataset, focusing on:
- Key trends or patterns observed
- Possible correlations or outliers
- Any interesting findings, including possible relationships between columns
- General observations and overall conclusions about the data

Dataset Summary:
{summary_text}

Please include information such as:
1. Significant trends or patterns in the data (e.g., age distribution, income ranges, etc.)
2. Key correlations or relationships between variables.
3. Potential anomalies or outliers that could be noteworthy.
4. Any other valuable insights based on the dataset.

Also, provide a brief conclusion summarizing the dataset's overall characteristics.
"""
        response = insight_pipeline(prompt, max_length=512, do_sample=True)
        return response[0]['generated_text']
    except Exception as e:
        return f"‚ùå AI Insight generation failed: {e}"

def run_pipeline():
    df = load_csv()  # Upload CSV from your device
    if df is None:
        print("‚ùå Failed to load CSV.")
        return

    print("\nüîç Dataset Summary:")
    summary = summarize_data(df)
    for k, v in summary.items():
        print(f"{k}: {v}\n")

    df = clean_data(df)
    print("\nüìä Generating visualizations...")
    generate_visuals(df)

    insights = generate_ai_insights(summary, df)
    print("\nüß† AI-Generated Insights:\n")
    print(insights)


if __name__ == "__main__":
    run_pipeline()

